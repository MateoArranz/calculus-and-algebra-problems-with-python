{"cells":[{"cell_type":"markdown","id":"5dbe7b9e","metadata":{},"source":["# Calculus and Algebra problems"]},{"cell_type":"markdown","id":"519c4b12","metadata":{},"source":["## Calculus\n","\n","Calculus is not obscure. It is the language for modeling behaviors. Calculus enables us to find the rate of changes in order to optimise a function. Without calculus, we would not be able to fully understand techniques such as:\n","\n","Backpropagation in neural networks\n","\n","Regression using optimal least square\n","\n","Expectation maximization in fitting probability models"]},{"cell_type":"markdown","id":"b7e2e87a","metadata":{},"source":["### Exercise 1\n","\n","Let’s say in my office, it takes me 10 seconds (time) to travel 25 meters (distance) to the coffee machine.\n","If we want to express the above situation as a function, then it would be:\n","\n","distance = speed * time\n","\n","So for this case, speed is the first derivative of the distance function above. As speed describes the rate of change of distance over time, when people say taking the first derivative of a certain function, they mean finding out the rate of change of a function.\n","\n","**Find the speed and build the linear function on distance $(d)$ over time $(t)$, when $(t ∈ [0,10])$.**"]},{"cell_type":"code","execution_count":1,"id":"bb3e954e","metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'panda'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m \n\u001b[1;32m      <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpanda\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m \n\u001b[1;32m      <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#define the distance function\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(x): \u001b[39mreturn\u001b[39;00m \u001b[39m2.5\u001b[39m\u001b[39m*\u001b[39mx \n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'panda'"]}],"source":["#import libraries\n","import matplotlib as plt \n","import numpy as np\n","import panda as pd \n","\n","#define the distance function\n","def f(x): return 2.5*x \n","x = np.linspace(0,10) "]},{"cell_type":"code","execution_count":null,"id":"dbc4c780","metadata":{},"outputs":[],"source":["#plot the distance function on domain(t)\n","plt.plot(x, f(x))"]},{"cell_type":"code","execution_count":null,"id":"4c4d4f20","metadata":{},"outputs":[],"source":["# create a dataframe\n","f1 = pd.DataFrame({'x': x, 'f(x)': f(x)})\n","f1.head() "]},{"cell_type":"markdown","id":"1144168d","metadata":{},"source":["### Exercise 2\n","\n","It turned out that I wasn't walking a constant speed towards getting my coffee but I was accelerating (my speed increased over time). If initial speed = 0, it still took me 10 seconds to travel from my seat to my coffee but I was walking faster and faster.\n","\n","$V_o$ = initial speed = $0$\n","\n","t = time\n","\n","a = acceleration\n","\n","**distance** = $V_o * t + 0.5 * a * (t^2)$\n","\n","**speed** = $V_o + a * t$\n","\n","The first derivative of the speed function is acceleration. I realise that the speed function is closely related to the distance function.\n","\n","**Find the acceleration value and build the quadratic function  $(t ∈ [0,10])$. Also create a graph and a table.**"]},{"cell_type":"code","execution_count":null,"id":"ec1f8bd7","metadata":{},"outputs":[],"source":["#define and plot the quadratic funtion\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def f(x): return 1/2*0.5*(x**2)\n","x = np.linspace(0,10)\n","plt.plot(x, f(x))"]},{"cell_type":"code","execution_count":null,"id":"ba5c497b","metadata":{},"outputs":[],"source":["#create a dataframe\n","f2 = pd.DataFrame({'x': x, 'f(x)': f(x)})\n","f2.head()"]},{"cell_type":"markdown","id":"66d4cc18","metadata":{},"source":["Before exercise 3, we'll make a brief introduction to Gradient Descent algorithm, which will have a larger explanation in future modules of the bootcamp.\n","\n","Gradient Descent algorithm is the hero behind the family of deep learning algorithms. When an algorithm in this family runs, it tries to minimize the error between the training input and predicted output. This minimization is done by optimization algorithms and gradient descent is the most popular one.\n","\n","Let’s say you have these input & output pairs:\n","\n","```py\n","input:\n","[\n"," [1,2],\n"," [3,4]\n","]\n","\n","output:\n","\n","[\n"," [50],\n"," [110]\n","]\n","```\n","We can estimate that if we multiply the input values by [10, 20], we can have the output as shown above.\n","```py\n","1(10) + 2(20) = 50\n","\n","3(10) + 4(20) = 110\n","```\n","When a machine learning algorithm starts running, it assigns random values and makes a prediction. \n","Let’s say it assigned [1,2] values:\n","```py\n","1(1) + 2(2) = 5\n","\n","3(1) + 4(2) = 11\n","```\n","Once it has the predictions, it calculates the error: the difference between the real data and the predicted data. There are many ways to calculate the error and they are called loss functions. \n","Once we have this value, the optimization algorithm starts showing itself and it sets new values which replace the initial random values. \n","\n","And, the loop continues until a condition is met. That condition can be to loop n times, or to loop until error is smaller than a value."]},{"cell_type":"markdown","id":"85ef2f0b","metadata":{},"source":["It can be hard to understand **gradient descent** without understanding **gradient**. So, let’s focus on what gradient is. The gradient shows the direction of the greatest change of a scalar function. The gradient calculation is done with derivatives, so let’s start with a simple example. To calculate the gradient, we just need to remember some linear algebra calculations from high school because we need to calculate derivatives.\n","\n","Let’s say we want to find the minimum point of $f(x) = x^2$. The derivative of that function is $df(x)=2x$. \n","\n","The gradient of $f(x)$ at point $x=-10$\n","\n","is \n","\n","$df(-10)=-20$.\n","\n","The gradient of $f(x)$ at point $x=1$\n","\n","is \n","\n","$df(1)=2$.\n","\n","Now let’s visualize $f(x)$ and those $x=-10$ and $x=1$ points."]},{"cell_type":"code","execution_count":null,"id":"4ff7e11a","metadata":{},"outputs":[],"source":["import numpy as np\n","import seaborn as sns\n","\n","def f(x):\n","    return x**2\n","\n","def df(x):\n","    return 2*x\n","\n","def visualize(f, x=None):\n","    \n","    xArray = np.linspace(-10, 10, 100) \n","    yArray = f(xArray)\n","    sns.lineplot(x=xArray, y=yArray)\n","    \n","    if x is not None:\n","        assert type(x) in [np.ndarray, list] # x should be numpy array or list\n","        if type(x) is list: # if it is a list, convert to numpy array\n","            x = np.array(x)\n","\n","            \n","        y = f(x)\n","        sns.scatterplot(x=x, y=y, color='red')"]},{"cell_type":"code","execution_count":null,"id":"633a54fd","metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["visualize(f, x=[-10, 1])"]},{"cell_type":"markdown","id":"9c187ad7","metadata":{},"source":["The red dot at x=-10 does not know the surface it stands on and it only knows the coordinates of where it stands and that the gradient of itself which is -20. And the other red dot at x=1 does not know the surface it stands on and it only knows the coordinates of where it stands and that the gradient of itself which is 2.\n","\n","By having only this information: we can say that the red dot at x=-10 should make a bigger jump than x=1 because it has a bigger absolute gradient value. The sign shows the direction. - shows that the red dot at x=-10 should move to the right and the other one should move to the left.\n","\n","In summary; the red dot at x=-10 (gradient: -20) should make a bigger jump to the right and the red dot at x=1 (gradient: 2) should make a smaller jump to the left. \n","\n","We know that the jump length should be proportional to the gradient, but what is that value exactly? We don’t know. So, let’s just say that red points should move with the length of alpha*gradient where alpha is just a parameter.\n","\n","We can say that the new location of the red dot should be calculated with the following formula:\n","\n","x = x - gradient * alpha"]},{"cell_type":"markdown","id":"0a7f5c3f","metadata":{},"source":["Now let's implement this with **Numpy**. Let’s start with visualizing $f(x)=x^2$ function and $x=-10$ point."]},{"cell_type":"code","execution_count":17,"id":"e26dbdf0","metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'visualize' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m visualize(f, x\u001b[39m=\u001b[39m[\u001b[39m-\u001b[39m\u001b[39m10\u001b[39m])\n","\u001b[0;31mNameError\u001b[0m: name 'visualize' is not defined"]}],"source":["visualize(f, x=[-10])"]},{"cell_type":"markdown","id":"6e752e19","metadata":{},"source":["The following code implements the whole logic explained before:"]},{"cell_type":"code","execution_count":16,"id":"2bdd54f1","metadata":{},"outputs":[],"source":["def gradient_descent(x, nsteps=1):\n","    \n","    \n","    #collectXs is an array to store how x changed in each iteration, \n","    #so we can visualize it later\n","    \n","    collectXs = [x]\n","    \n","    #learning_rate is the value that we mentioned as alpha in previous section\n","    \n","    learning_rate = 1e-01\n","    \n","    for _ in range(nsteps):\n","        \n","        #the following one line does the real magic\n","        #the next value of x is calculated by subtracting the gradient*learning_rate by itself\n","        #the intuation behind this line is in the previous section\n","        \n","        x -= df(x) * learning_rate \n","        collectXs.append(x)\n","        \n","    #we return a tuple that contains\n","    #x -> recent x after nsteps \n","    #collectXs -> all the x values that was calculated so far\n","    \n","    return x, collectXs"]},{"cell_type":"markdown","id":"aea74a65","metadata":{},"source":["Before running gradient descent with 1000 steps, let’s just run it twice, one step at a time to see how x evolves. \n","We start with x=-10 and it evolves to x=-8. We know that when x=0 that is the **minimum point**, so, yes it is evolving in the correct direction."]},{"cell_type":"code","execution_count":13,"id":"0350981e","metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'gradient_descent' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m x\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m10\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m x, collectedXs \u001b[39m=\u001b[39m gradient_descent(x, nsteps\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(x)\n","\u001b[0;31mNameError\u001b[0m: name 'gradient_descent' is not defined"]}],"source":["x=-10\n","x, collectedXs = gradient_descent(x, nsteps=1)\n","print(x)"]},{"cell_type":"code","execution_count":15,"id":"f8e01e2d","metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'gradient_descent' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#The next step will start at x=-8. Let's run gradient for 1 step\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m x, collectedXs \u001b[39m=\u001b[39m gradient_descent(x, nsteps\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(x)\n","\u001b[0;31mNameError\u001b[0m: name 'gradient_descent' is not defined"]}],"source":["#The next step will start at x=-8. Let's run gradient for 1 step\n","\n","x, collectedXs = gradient_descent(x, nsteps=1)\n","print(x)"]},{"cell_type":"markdown","id":"93f13b32","metadata":{},"source":["It goes to x=-6.4. Excelent. Now let's run it 1000 times"]},{"cell_type":"code","execution_count":11,"id":"b699d1fb","metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'gradient_descent' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m x, collectedXs \u001b[39m=\u001b[39m gradient_descent(x, nsteps\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(x)\n","\u001b[0;31mNameError\u001b[0m: name 'gradient_descent' is not defined"]}],"source":["x, collectedXs = gradient_descent(x, nsteps=1000)\n","print(x)"]},{"cell_type":"code","execution_count":12,"id":"0b76ee22","metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'visualize' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m visualize(f, x\u001b[39m=\u001b[39mcollectedXs)\n","\u001b[0;31mNameError\u001b[0m: name 'visualize' is not defined"]}],"source":["visualize(f, x=collectedXs)"]},{"cell_type":"markdown","id":"d00d2fbb","metadata":{},"source":["### Exercise 3\n","\n","When I arrive to the coffee machine, I hear my colleague talking about the per-unit costs of producing 'product B' for the company. As the company produces more units, the per-unit costs continue to decrease until a point where it starts to increase.\n","\n","To optimise the per-unit production cost at its minimal to optimise efficiency, the company would need to find the number of units to be produced where the per-unit production costs begin to change from decreasing to increasing.\n","\n","**Build a quadratic function $f(x)=0.1(x)^2−9x +4500$ on $x∈[0,100]$  to create the per-unit cost function, and make a conclusion.**"]},{"cell_type":"code","execution_count":10,"id":"7c67d8b7","metadata":{},"outputs":[{"ename":"AttributeError","evalue":"module 'matplotlib' has no attribute 'plot'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb Cell 26\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0.1\u001b[39m \u001b[39m*\u001b[39m (x)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m-\u001b[39m \u001b[39m9\u001b[39m \u001b[39m*\u001b[39m x \u001b[39m+\u001b[39m \u001b[39m4500\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39m0\u001b[39m, \u001b[39m100\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://mateoarranz-calculusand-c8i0j1i19tb.ws-eu108.gitpod.io/workspace/calculus-and-algebra-problems-with-python/notebook/problems.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39;49mplot(x, f(x))\n","File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/matplotlib/_api/__init__.py:217\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m props:\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m props[name]\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance)\n\u001b[0;32m--> 217\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    218\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'plot'"]}],"source":["#define and plot the funtion\n","\n","def f(x):\n","    return 0.1 * (x)**2 - 9 * x + 4500\n","\n","x = np.linspace(0, 100)\n","plt.plot(x, f(x))"]},{"cell_type":"markdown","id":"fbe54895","metadata":{},"source":["We saw with Gradient Descent how the red dot navigates in an environment it does not know about. It only knows the coordinates of where it is and its gradient. The red dot could find the minimum point by using only this knowledge and gradient descent algorithm.\n","\n","**Optional:**\n","\n","Implement all the previous steps to create a gradient descent algorithm to see how the per-unit cost evolves, with a starting point of 0 units of production."]},{"cell_type":"markdown","id":"aabad82c","metadata":{},"source":["## Linear Algebra"]},{"cell_type":"markdown","id":"6753636d","metadata":{},"source":["### Exercise 1 : Sum of two matrices\n","\n","Suppose we have two matrices A and B.\n","```py\n","A = [[1,2],[3,4]]\n","B = [[4,5],[6,7]]\n","\n","then we get\n","A+B = [[5,7],[9,11]]\n","A-B = [[-3,-3],[-3,-3]]\n","```\n","\n","Make the sum of two matrices using Python with Numpy"]},{"cell_type":"code","execution_count":9,"id":"9e200c32","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Printing elements of first matrix\n","[[1 2]\n"," [3 4]]\n","Printing elements of second matrix\n","[[4 5]\n"," [6 7]]\n","Addition of two matrix\n","[[ 5  7]\n"," [ 9 11]]\n"]}],"source":["# importing numpy as np\n","import numpy as np \n"," \n"," \n","# creating first matrix\n","A = np.array([[1, 2], [3, 4]])\n"," \n","# creating second matrix\n","B = np.array([[4, 5], [6, 7]])\n"," \n","#print elements\n","print(\"Printing elements of first matrix\")\n","print(A)\n","print(\"Printing elements of second matrix\")\n","print(B)\n","\n","# adding two matrix\n","print(\"Addition of two matrix\")\n","print(np.add(A, B))"]},{"cell_type":"markdown","id":"93bfb6cc","metadata":{},"source":["### Exercise 2: Sum of two lists\n","\n","There will be many situations in which we'll have to find index wise summation of two different lists. This can have possible applications in day-to-day programming. In this exercise we will solve the same problem with various ways in which this task can be performed.\n","\n","We have the following two lists:\n","```py\n","list1 = [2, 5, 4, 7, 3]\n","list2 = [1, 4, 6, 9, 10]\n","```\n","\n","Now let's use Python code to demonstrate addition of two lists.\n"]},{"cell_type":"code","execution_count":8,"id":"867b70fc","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original list 1 : [2, 5, 4, 7, 3]\n","Original list 2 : [1, 4, 6, 9, 10]\n","Resultant list is : [3, 9, 10, 16, 13]\n"]}],"source":["# Naive method\n","\n","# initializing lists\n","list1 = [2, 5, 4, 7, 3]\n","list2 = [1, 4, 6, 9, 10]\n"," \n","# printing original lists\n","print (\"Original list 1 : \" + str(list1))\n","print (\"Original list 2 : \" + str(list2))\n"," \n","# using naive method to \n","# add two list \n","res_list = []\n","for i in range(0, len(list1)):\n"," res_list.append(list1[i] + list2[i])\n"," \n","# printing resultant list \n","print (\"Resultant list is : \" + str(res_list))"]},{"cell_type":"markdown","id":"7a063d7f","metadata":{},"source":["Now use the following three different methods to make the same calculation: sum of two lists"]},{"cell_type":"code","execution_count":7,"id":"681930a3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original list 1 : [1, 3, 4, 6, 8]\n","Original list 2 : [4, 5, 6, 2, 10]\n","Resultant list is : [5, 8, 10, 8, 18]\n"]}],"source":["# Use list comprehensions to perform addition of the two lists:\n","\n","# initializing lists\n","list1 = [1, 3, 4, 6, 8]\n","list2 = [4, 5, 6, 2, 10]\n"," \n","# printing original lists\n","print(\"Original list 1 : \" + str(list1))\n","print(\"Original list 2 : \" + str(list2))\n"," \n","# using list comprehension to add two list \n","res_list = [list1[i] + list2[i] for i in range(len(list1))]\n"," \n","# printing resultant list \n","print(\"Resultant list is : \" + str(res_list))"]},{"cell_type":"code","execution_count":6,"id":"a3a8a425","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original list 1: [1, 3, 4, 6, 8]\n","Original list 2: [4, 5, 6, 2, 10]\n","Resultant list is: [5, 8, 10, 8, 18]\n"]}],"source":["# Use map() + add():\n","from operator import add\n","# initializing lists\n","list1 = [1, 3, 4, 6, 8]\n","list2 = [4, 5, 6, 2, 10]\n"," \n","# printing original lists\n","print(\"Original list 1:\", list1)\n","print(\"Original list 2:\", list2)\n"," \n","# using map() + add() to add two list \n","res_list = list(map(add, list1, list2))\n"," \n","# printing resultant list \n","print(\"Resultant list is:\", res_list)"]},{"cell_type":"code","execution_count":5,"id":"1708d7ee","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original list 1: [1, 3, 4, 6, 8]\n","Original list 2: [4, 5, 6, 2, 10]\n","Resultant list is: [5, 8, 10, 8, 18]\n"]}],"source":["# Use zip() + sum():\n","from operator import add\n","# initializing lists\n","list1 = [1, 3, 4, 6, 8]\n","list2 = [4, 5, 6, 2, 10]\n"," \n","# printing original lists\n","print(\"Original list 1:\", list1)\n","print(\"Original list 2:\", list2)\n"," \n","# Using zip() + sum() to add two list \n","res_list = [sum(i) for i in zip(list1, list2)]\n"," \n","# printing resultant list \n","print(\"Resultant list is:\", res_list)"]},{"cell_type":"markdown","id":"1aef1bd2","metadata":{},"source":["### Exercise 3 : Dot multiplication\n","\n","We have two matrices:\n","```py\n","matrix1 = [[1,7,3],\n"," [ 4,5,2],\n"," [ 3,6,1]]\n","matrix2 = [[5,4,1],\n"," [ 1,2,3],\n"," [ 4,5,2]]\n","```\n","\n","A simple technique but expensive method for larger input datasets is using for loops. In this exercise we will first use nested for loops to iterate through each row and column of the matrices, and then we will perform the same multiplication using Numpy."]},{"cell_type":"code","execution_count":null,"id":"840e7d0e","metadata":{},"outputs":[],"source":["#Using a for loop input two matrices of size n x m\n","matrix1 = [[1,7,3],\n"," [ 4,5,2],\n"," [ 3,6,1]]\n","matrix2 = [[5,4,1],\n"," [ 1,2,3],\n"," [ 4,5,2]]\n"," \n","res = [[0 for x in range(3)] for y in range(3)]\n"," \n","# explicit for loops\n","for i in range(len(matrix1)):\n","    for j in range(len(matrix2[0])):\n","        for k in range(len(matrix2)):\n"," \n"," # resulted matrix\n"," res[i][j] += matrix1[i][k] * matrix2[k][j]\n"," \n","print (res)"]},{"cell_type":"code","execution_count":4,"id":"db6c3355","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[24 33 28]\n"," [33 36 23]\n"," [25 29 23]]\n"]}],"source":["# Import libraries\n","import numpy as np \n"," \n","# input two matrices\n","matrix1 = ([1, 7, 3],[4, 5, 2],[3, 6, 1])\n","matrix2 = ([5, 4, 1],[1, 2, 3],[4, 5, 2])\n","# This will return dot product\n","res = np.dot(matrix1, matrix2)\n"," \n","# print resulted matrix\n","print(res)"]},{"cell_type":"markdown","id":"785f6c30","metadata":{},"source":["\n","https://www.youtube.com/channel/UCXq-PLvYAX-EufF5RAPihVg\n","\n","https://www.geeksforgeeks.org/\n","\n","https://medium.com/@seehleung/basic-calculus-explained-for-machine-learning-c7f642e7ced3\n","\n","https://blog.demir.io/understanding-gradient-descent-266fc3dcf02f"]}],"metadata":{"interpreter":{"hash":"d3463682613d55fcbb64853e38cc3520a7f67bdf8d6940e781ddcdc423122719"},"kernelspec":{"display_name":"Python 3.9.12 ('calculus-project')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":5}
